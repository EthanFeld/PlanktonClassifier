{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import os\n","import pickle"],"metadata":{"id":"VGQA1ZlhDn2W","executionInfo":{"status":"ok","timestamp":1755622377839,"user_tz":420,"elapsed":22,"user":{"displayName":"Emily Hong","userId":"09138489315252249845"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VytfGe8Beqke","outputId":"820af1f4-7bd9-4090-93d5-6717cc9804e7","executionInfo":{"status":"ok","timestamp":1755622379394,"user_tz":420,"elapsed":681,"user":{"displayName":"Emily Hong","userId":"09138489315252249845"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["DATA VISUALIZATION\n"],"metadata":{"id":"7Kr0_rF-N7hA"}},{"cell_type":"code","source":["# load images\n","with open(\"/content/drive/MyDrive/Plankton/image_dataframe.pkl\", \"rb\") as f:\n","    df = pickle.load(f)\n","\n","print(df.head())\n","print(df.columns)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08IJJSm-N-Bk","executionInfo":{"status":"ok","timestamp":1755622869673,"user_tz":420,"elapsed":484,"user":{"displayName":"Emily Hong","userId":"09138489315252249845"}},"outputId":"ab06e211-b454-471e-fee3-4bf0d5174a63"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["  Image_Class                                       Image_Matrix\n","0         mix  [[204, 204, 204, 203, 203, 203, 203, 200, 202,...\n","1         mix  [[200, 201, 203, 201, 199, 200, 202, 201, 199,...\n","2         mix  [[221, 222, 223, 224, 223, 222, 221, 222, 222,...\n","3         mix  [[192, 191, 188, 183, 182, 189, 185, 180, 185,...\n","4         mix  [[212, 212, 212, 212, 213, 213, 213, 211, 212,...\n","Index(['Image_Class', 'Image_Matrix'], dtype='object')\n"]}]},{"cell_type":"code","source":["counts = df[\"Image_Class\"].value_counts()\n","print(counts)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_53ECxION9-K","executionInfo":{"status":"ok","timestamp":1755622485374,"user_tz":420,"elapsed":68,"user":{"displayName":"Emily Hong","userId":"09138489315252249845"}},"outputId":"110a6fa2-85e6-465f-c8d9-45f6b9755dfc"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Image_Class\n","mix                      500\n","Ciliate_mix              500\n","Dactyliosolen            500\n","Cerataulina              500\n","mix_elongated            500\n","Cylindrotheca            500\n","Mesodinium_sp            500\n","DactFragCerataul         500\n","Guinardia_striata        500\n","Ditylum                  500\n","Asterionellopsis         500\n","Chaetoceros              500\n","Leptocylindrus           500\n","G_delicatula_parasite    500\n","bad                      500\n","Corethron                500\n","Dictyocha                500\n","Guinardia_delicatula     500\n","flagellate_sp3           500\n","Dinobryon                500\n","detritus                 500\n","dino30                   500\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GccSlRNiN97U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"euaHmK_tN94N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-XdK_86GN9xj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mKRscoKsN9uI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xZLAUpScN9kw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"QuUaW4QzN9GS"}},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","# Path to your zip file\n","zip_path = '/content/drive/MyDrive/Plankton/WHOI_raw_data/2013.zip'\n","\n","# Extract to the same directory as the zip file\n","extract_path = '/content/drive/MyDrive/Plankton/WHOI_raw_data/'\n","\n","# Create the extraction directory if it doesn't exist\n","os.makedirs(extract_path, exist_ok=True)\n","\n","# Unzip the file\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(f\"Successfully extracted to {extract_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"ZYjNLYZaerJt","outputId":"77f34e2b-3716-4ce4-e216-158c71de09bb","executionInfo":{"status":"error","timestamp":1755621881921,"user_tz":420,"elapsed":598,"user":{"displayName":"Emily Hong","userId":"09138489315252249845"}}},"execution_count":5,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3453295571.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Unzip the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1477\u001b[0m             x.date_time = ( (d>>9)+1980, (d>>5)&0xF, d&0x1F,\n\u001b[1;32m   1478\u001b[0m                             t>>11, (t>>5)&0x3F, (t&0x1F) * 2 )\n\u001b[0;32m-> 1479\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decodeExtra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_filename_crc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader_offset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m_decodeExtra\u001b[0;34m(self, filename_crc)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflag_bits\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0m_MASK_UTF_FILENAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_decodeExtra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_crc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m         \u001b[0;31m# Try to decode the extra field.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mextra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## LOAD DATASET"],"metadata":{"id":"X7WeeEQb9dSG"}},{"cell_type":"code","source":["folder_paths = ['/content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2007', '/content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2013', '/content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2014']"],"metadata":{"id":"4Bq3ug_oe_RI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_images_data = []\n","\n","for folder_path in folder_paths:\n","    print(f\"--> Processing main folder: {folder_path}\")\n","\n","    for root, subdirs, files in os.walk(folder_path):\n","        if files:\n","            image_class = os.path.basename(root)\n","\n","            for file_name in files:\n","                file_path = os.path.join(root, file_name)\n","\n","                all_images_data.append({\n","                    'Image Class': image_class,\n","                    'Image Path': file_path\n","                })\n","\n","print(\"\\n...Processing complete!\")\n","\n","# 4. Create a Pandas DataFrame from the collected data\n","df = pd.DataFrame(all_images_data)\n","\n","# 5. Display information about the final DataFrame\n","print(\"\\n--- Combined DataFrame ---\")\n","print(f\"Total number of images found: {len(df)}\")\n","print(f\"Number of unique classes found: {df['Image Class'].nunique()}\")\n","\n","print(\"\\nFirst 5 rows of the DataFrame:\")\n","print(df.head())\n","\n","print(\"\\nLast 5 rows of the DataFrame:\")\n","print(df.tail())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HIAZZAtzH9p6","outputId":"2df9d4ab-ab54-4c2e-ceee-b5dbe0dbf23a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting to process folders...\n","--> Processing main folder: /content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2007\n","--> Processing main folder: /content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2013\n","--> Processing main folder: /content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2014\n","\n","...Processing complete!\n","\n","--- Combined DataFrame ---\n","Total number of images found: 581892\n","Number of unique classes found: 98\n","\n","First 5 rows of the DataFrame:\n","        Image Class                                         Image Path\n","0         Bidulphia  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","1         Bidulphia  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","2         Bidulphia  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","3  Asterionellopsis  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","4  Asterionellopsis  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","\n","Last 5 rows of the DataFrame:\n","       Image Class                                         Image Path\n","581887  Licmophora  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","581888  Licmophora  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","581889  Licmophora  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","581890  Licmophora  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","581891  Licmophora  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n"]}]},{"cell_type":"code","source":["df.shape, df['Image Class'], df['Image Path']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rK0ztE-OM9od","outputId":"898f64b6-2bca-4a4a-db98-7f5a46771352"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((581892, 2),\n"," 0                Bidulphia\n"," 1                Bidulphia\n"," 2                Bidulphia\n"," 3         Asterionellopsis\n"," 4         Asterionellopsis\n","                 ...       \n"," 581887          Licmophora\n"," 581888          Licmophora\n"," 581889          Licmophora\n"," 581890          Licmophora\n"," 581891          Licmophora\n"," Name: Image Class, Length: 581892, dtype: object,\n"," 0         /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n"," 1         /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n"," 2         /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n"," 3         /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n"," 4         /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","                                 ...                        \n"," 581887    /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n"," 581888    /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n"," 581889    /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n"," 581890    /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n"," 581891    /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n"," Name: Image Path, Length: 581892, dtype: object)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["import cv2\n","import numpy as np"],"metadata":{"id":"LUTRzIR2P3F5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## LOAD DATASET TO IMAGES"],"metadata":{"id":"1s5Q0ZubQVZP"}},{"cell_type":"code","source":["folder_paths = ['/content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2007', '/content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2013', '/content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2014']\n","IMAGE_WIDTH = 64\n","IMAGE_HEIGHT = 64\n","\n","all_images_data = []\n","\n","print(\"--- Starting to Scan Image Folders ---\")\n","for folder_path in folder_paths:\n","    print(f\"--> Processing main folder: {folder_path}\")\n","\n","    for root, subdirs, files in os.walk(folder_path):\n","        if files:\n","            image_class = os.path.basename(root)\n","\n","            for file_name in files:\n","                file_path = os.path.join(root, file_name)\n","\n","                # Append the data to our list\n","                all_images_data.append({\n","                    'Image Class': image_class,\n","                    'Image Path': file_path\n","                })\n","\n","print(\"\\n...Initial file scan complete!\")\n","\n","# Create a Pandas DataFrame from the collected path data\n","path_df = pd.DataFrame(all_images_data)\n","\n","if path_df.empty:\n","    print(\"\\nError: No images were found. Please check your 'folder_paths'.\")\n","else:\n","    print(\"\\n--- Initial DataFrame with Image Paths ---\")\n","    print(f\"Total number of images found: {len(path_df)}\")\n","    print(f\"Number of unique classes found: {path_df['Image Class'].nunique()}\")\n","    print(\"\\nFirst 5 rows:\")\n","    print(path_df.head())\n","\n","    # --- 2. Create New DataFrame with Image Matrices ---\n","    # This is the new part that processes the images into numerical data.\n","\n","    processed_images_data = []\n","    total_images = len(path_df)\n","\n","    print(f\"\\n--- Processing Images into Numerical Matrices ({IMAGE_WIDTH}x{IMAGE_HEIGHT}) ---\")\n","\n","    for index, row in path_df.iterrows():\n","        image_path = row['Image Path']\n","        image_class = row['Image Class']\n","\n","        try:\n","            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","\n","            # Resize the image to a consistent size\n","            resized_img = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\n","\n","            processed_images_data.append({\n","                'Image Class': image_class,\n","                'Image Matrix': resized_img\n","            })\n","\n","            # Print progress\n","            if (index + 1) % 10000 == 0:\n","              print(f\"Processing image {index + 1}/{total_images}...\")\n","\n","        except Exception as e:\n","            print(f\"\\nError processing image {image_path}: {e}\")\n","\n","    print(\"\\n\\n...Image processing complete!\")\n","\n","    # 3. Create the final DataFrame with numerical data\n","    image_matrix_df = pd.DataFrame(processed_images_data)\n","\n","    # 4. Display information about the final DataFrame\n","    if not image_matrix_df.empty:\n","        print(\"\\n--- Final DataFrame with Image Matrices ---\")\n","        print(f\"Total number of images processed: {len(image_matrix_df)}\")\n","        print(\"\\nFirst 5 rows of the new DataFrame:\")\n","        print(image_matrix_df.head())\n","\n","        # You can access a specific image matrix like this:\n","        print(\"\\nExample of one image matrix from the DataFrame:\")\n","        # .iloc[0] gets the first row, ['Image Matrix'] gets the matrix itself\n","        example_matrix = image_matrix_df.iloc[0]['Image Matrix']\n","        print(example_matrix)\n","        print(f\"Shape of the matrix: {example_matrix.shape}\")\n","    else:\n","        print(\"\\nCould not create the final DataFrame as no images were processed successfully.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Caq2oJ6P4bd","outputId":"648f4b77-2324-4303-ef80-a067caab34d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting to Scan Image Folders ---\n","--> Processing main folder: /content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2007\n","--> Processing main folder: /content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2013\n","--> Processing main folder: /content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2014\n","\n","...Initial file scan complete!\n","\n","--- Initial DataFrame with Image Paths ---\n","Total number of images found: 552006\n","Number of unique classes found: 98\n","\n","First 5 rows:\n","        Image Class                                         Image Path\n","0         Bidulphia  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","1         Bidulphia  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","2         Bidulphia  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","3  Asterionellopsis  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","4  Asterionellopsis  /content/drive/MyDrive/Data/Plankton/WHOI_unzi...\n","\n","--- Processing Images into Numerical Matrices (64x64) ---\n","\n","Error processing image /content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2007/Bidulphia/Thumbs.db: OpenCV(4.12.0) /io/opencv/modules/imgproc/src/resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yXzvc9NCQ8Jp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qovREer3Q8HB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SzK69NBtQ8Cf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Egi1EHokQ75K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get all items in the main folder\n","folder_path = folder_paths[1]\n","items = os.listdir(folder_path)\n","\n","# Filter to get only directories\n","subfolders = [item for item in items if os.path.isdir(os.path.join(folder_path, item))]\n","\n","print(f\"Found {len(subfolders)} subfolders in {folder_path}:\")\n","print(\"-\" * 50)\n","\n","# Print each subfolder name and count files in it\n","for subfolder in sorted(subfolders):\n","    subfolder_path = os.path.join(folder_path, subfolder)\n","\n","    # Count files in the subfolder\n","    try:\n","        files = [f for f in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, f))]\n","        file_count = len(files)\n","        print(f\"{subfolder}: {file_count} files\")\n","    except PermissionError:\n","        print(f\"{subfolder}: Permission denied\")\n","    except Exception as e:\n","        print(f\"{subfolder}: Error - {e}\")\n","\n","print(\"-\" * 50)\n","print(f\"Total subfolders processed: {len(subfolders)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TpBkKkE--W9l","outputId":"f9f23fd5-c863-4651-f9a2-c1b853ab90ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 65 subfolders in /content/drive/MyDrive/Data/Plankton/WHOI_unzipped_data/2014:\n","--------------------------------------------------\n","Akashiwo: 2 files\n","Amphidinium_sp: 66 files\n","Asterionellopsis: 128 files\n","Bacillaria: 0 files\n","Bidulphia: 0 files\n","Cerataulina: 412 files\n","Cerataulina_flagellate: 5 files\n","Ceratium: 6 files\n","Chaetoceros: 1871 files\n","Chaetoceros_didymus: 11 files\n","Chaetoceros_didymus_flagellate: 1 files\n","Chaetoceros_flagellate: 4 files\n","Chaetoceros_other: 9 files\n","Chaetoceros_pennate: 6 files\n","Chrysochromulina: 48 files\n","Ciliate_mix: 1074 files\n","Cochlodinium: 4 files\n","Corethron: 447 files\n","Coscinodiscus: 17 files\n","Cylindrotheca: 2345 files\n","DactFragCerataul: 175 files\n","Dactyliosolen: 532 files\n","Delphineis: 55 files\n","Dictyocha: 61 files\n","Didinium_sp: 7 files\n","Dinobryon: 588 files\n","Dinophysis: 13 files\n","Ditylum: 217 files\n","Ditylum_parasite: 22 files\n","Emiliania_huxleyi: 8 files\n","Ephemera: 23 files\n","Eucampia: 44 files\n","Euglena: 19 files\n","Euplotes_sp: 3 files\n","G_delicatula_detritus: 1 files\n","G_delicatula_external_parasite: 9 files\n","G_delicatula_parasite: 57 files\n","Gonyaulax: 0 files\n","Guinardia_delicatula: 949 files\n","Guinardia_flaccida: 43 files\n","Guinardia_striata: 447 files\n","Gyrodinium: 58 files\n","Hemiaulus: 0 files\n","Heterocapsa_triquetra: 67 files\n","Karenia: 0 files\n","Katodinium_or_Torodinium: 31 files\n","Laboea_strobila: 9 files\n","Lauderia: 1 files\n","Leegaardiella_ovalis: 3 files\n","Leptocylindrus: 4246 files\n","Leptocylindrus_mediterraneus: 31 files\n","Licmophora: 14 files\n","Mesodinium_sp: 107 files\n","amoeba: 71 files\n","bad: 10 files\n","bead: 17 files\n","bubble: 0 files\n","clusterflagellate: 8 files\n","detritus: 36346 files\n","diatom_flagellate: 24 files\n","dino30: 3816 files\n","dino_large1: 5 files\n","flagellate_sp3: 177 files\n","kiteflagellates: 4 files\n","mix: 27642 files\n","--------------------------------------------------\n","Total subfolders processed: 65\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_0L7TSoP-hxK"},"execution_count":null,"outputs":[]}]}